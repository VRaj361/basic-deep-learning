{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbqn7lPwFOVAs2JEMOgozO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VRaj361/basic-deep-learning/blob/master/Gradient_Decent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kqIsTbY4na6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "inp1 = [0.5,0.25]\n",
        "inp2 = [0.2,0.9]\n",
        "\n",
        "def sigmoid(w,b,x):\n",
        "  return 1.0/(1.0 + np.exp(-(w*x+b)))\n",
        "\n",
        "def grab_w(w,b,x,y):\n",
        "  fx = sigmoid(w,b,x)\n",
        "  return (fx - y) * x * (1-fx) * fx\n",
        "\n",
        "def grab_b(w,b,x,y):\n",
        "  fx = sigmoid(w,b,x)\n",
        "  return (fx - y) * (1-fx) * fx\n",
        "\n",
        "def do_gradiend_descent():\n",
        "  w ,b ,eta, max_epochs = -2, -2, 1, 1000\n",
        "  for i in range(max_epochs):\n",
        "    dw, db = 0,0\n",
        "    for x,y in zip(inp1,inp2):\n",
        "      dw+=grab_w(w,b,x,y)\n",
        "      db+=grab_b(w,b,x,y)\n",
        "    #modify the weight and bais\n",
        "    w = w - eta * dw\n",
        "    b = b - eta * db\n",
        "    print('weight-> ',w , 'bais-> ',b)\n",
        "    \n",
        "  print('error-> ',error(w,b))\n",
        "\n",
        "def do_momentum_gradient_descent():\n",
        "  w,b,eta,max_epochs =-2,-2,1.0,100\n",
        "  prev_v_w,prev_v_b,gamma=0,0,0.9\n",
        "  for i in range(max_epochs):\n",
        "    dw,db=0,0\n",
        "    for x,y in zip(inp1,inp2):\n",
        "      dw+=grab_w(w,b,x,y)\n",
        "      db+=grab_b(w,b,x,y)\n",
        "    v_w=gamma*prev_v_w+eta*dw\n",
        "    v_b=gamma*prev_v_b+eta*db\n",
        "    w=w-v_w\n",
        "    b=b-v_b\n",
        "    prev_v_w=v_w\n",
        "    prev_v_b=v_b\n",
        "    print('weight-> ',w , 'bais-> ',b,)\n",
        "    print('error->',error(w,b))\n",
        "    print()\n",
        "\n",
        "def do_nesterov_accelerated_gradient_descent():\n",
        "  w,b,eta,max_epochs =-2,-2,0.01,100\n",
        "  prev_v_w,prev_v_b,gamma=0,0,0.9\n",
        "  for i in range(max_epochs):\n",
        "    dw,db=0,0\n",
        "    v_w=gamma*prev_v_w\n",
        "    v_b=gamma*prev_v_b\n",
        "    for x,y in zip(inp1,inp2):\n",
        "      dw+=grab_w(w-v_w,b-v_b,x,y)\n",
        "      db+=grab_b(w-v_w,b-v_b,x,y)\n",
        "    v_w=gamma*prev_v_w+eta*dw\n",
        "    v_b=gamma*prev_v_b+eta*db\n",
        "    w=w-v_w\n",
        "    b=b-v_b\n",
        "    prev_v_w=v_w\n",
        "    prev_v_b=v_b\n",
        "    print('weight-> ',w , 'bais-> ',b)\n",
        "    print('error->',error(w,b))\n",
        "    print()\n",
        "\n",
        "\n",
        "def error(w,b):\n",
        "  err = 0\n",
        "  for x,y in zip(inp1,inp2):\n",
        "    fx = sigmoid(w,b,x)\n",
        "    err += 0.5 * (fx - y) ** 2\n",
        "  return err;\n",
        "\n",
        "\n",
        "# do_gradiend_descent()\n",
        "# do_momentum_gradient_descent()\n",
        "do_nesterov_accelerated_gradient_descent()"
      ]
    }
  ]
}